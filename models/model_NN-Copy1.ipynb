{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn,math, itertools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"evaluations.csv\")\n",
    "\n",
    "\n",
    "#dropping outliers (3 std above mean)\n",
    "#dropping draws\n",
    "#boolean variables?\n",
    "#dropping opening and endgame\n",
    "#visualize distributions\n",
    "#balance classes => makes predicitons equal \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404744\n"
     ]
    }
   ],
   "source": [
    "feature_cols = data.columns[4:]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353261"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##dropping duplicate fens, keeping one\n",
    "len(data[data[\"fen\"].duplicated()][\"fen\"].unique())\n",
    "data = data.drop_duplicates(subset=['fen'], keep='last')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133539\n",
      "103474\n",
      "116248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>move number</th>\n",
       "      <th>total moves</th>\n",
       "      <th>W_material sum</th>\n",
       "      <th>W_pawn control</th>\n",
       "      <th>W_piece squares sum</th>\n",
       "      <th>W_diagonal control</th>\n",
       "      <th>W_center control</th>\n",
       "      <th>W_doubled pawns</th>\n",
       "      <th>W_mobility</th>\n",
       "      <th>W_both bishops</th>\n",
       "      <th>...</th>\n",
       "      <th>B_piece squares sum</th>\n",
       "      <th>B_diagonal control</th>\n",
       "      <th>B_center control</th>\n",
       "      <th>B_doubled pawns</th>\n",
       "      <th>B_mobility</th>\n",
       "      <th>B_both bishops</th>\n",
       "      <th>B_not all pawns</th>\n",
       "      <th>B_pinned evaluation</th>\n",
       "      <th>B_attacker evalutation</th>\n",
       "      <th>B_has queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.00000</td>\n",
       "      <td>200000.00000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>47.569775</td>\n",
       "      <td>96.136390</td>\n",
       "      <td>25.99282</td>\n",
       "      <td>2.05351</td>\n",
       "      <td>2694.643840</td>\n",
       "      <td>0.364615</td>\n",
       "      <td>4.732880</td>\n",
       "      <td>0.142470</td>\n",
       "      <td>31.543205</td>\n",
       "      <td>0.389210</td>\n",
       "      <td>...</td>\n",
       "      <td>-2685.581445</td>\n",
       "      <td>-0.440135</td>\n",
       "      <td>-4.128925</td>\n",
       "      <td>-0.122585</td>\n",
       "      <td>-31.543205</td>\n",
       "      <td>-0.386875</td>\n",
       "      <td>-0.879410</td>\n",
       "      <td>-0.150080</td>\n",
       "      <td>-3.641950</td>\n",
       "      <td>-0.686355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>34.162997</td>\n",
       "      <td>34.491787</td>\n",
       "      <td>10.42592</td>\n",
       "      <td>0.70112</td>\n",
       "      <td>1117.594127</td>\n",
       "      <td>0.570169</td>\n",
       "      <td>2.005686</td>\n",
       "      <td>0.366078</td>\n",
       "      <td>11.501664</td>\n",
       "      <td>0.487572</td>\n",
       "      <td>...</td>\n",
       "      <td>1110.500245</td>\n",
       "      <td>0.591141</td>\n",
       "      <td>1.795731</td>\n",
       "      <td>0.342722</td>\n",
       "      <td>11.501664</td>\n",
       "      <td>0.487036</td>\n",
       "      <td>0.325651</td>\n",
       "      <td>0.687342</td>\n",
       "      <td>3.351823</td>\n",
       "      <td>0.464621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4647.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1751.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3651.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2922.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3669.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1745.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4747.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         move number    total moves  W_material sum  W_pawn control  \\\n",
       "count  200000.000000  200000.000000    200000.00000    200000.00000   \n",
       "mean       47.569775      96.136390        25.99282         2.05351   \n",
       "std        34.162997      34.491787        10.42592         0.70112   \n",
       "min         0.000000      10.000000         0.00000         0.00000   \n",
       "25%        21.000000      72.000000        17.00000         2.00000   \n",
       "50%        42.000000      90.000000        28.00000         2.00000   \n",
       "75%        67.000000     115.000000        35.00000         2.00000   \n",
       "max       318.000000     322.000000        44.00000         4.00000   \n",
       "\n",
       "       W_piece squares sum  W_diagonal control  W_center control  \\\n",
       "count        200000.000000       200000.000000     200000.000000   \n",
       "mean           2694.643840            0.364615          4.732880   \n",
       "std            1117.594127            0.570169          2.005686   \n",
       "min             -65.000000            0.000000          0.000000   \n",
       "25%            1751.000000            0.000000          3.000000   \n",
       "50%            2930.000000            0.000000          5.000000   \n",
       "75%            3669.000000            1.000000          6.000000   \n",
       "max            4747.000000            3.000000         12.000000   \n",
       "\n",
       "       W_doubled pawns     W_mobility  W_both bishops  ...  \\\n",
       "count    200000.000000  200000.000000   200000.000000  ...   \n",
       "mean          0.142470      31.543205        0.389210  ...   \n",
       "std           0.366078      11.501664        0.487572  ...   \n",
       "min           0.000000       0.000000        0.000000  ...   \n",
       "25%           0.000000      26.000000        0.000000  ...   \n",
       "50%           0.000000      34.000000        0.000000  ...   \n",
       "75%           0.000000      39.000000        1.000000  ...   \n",
       "max           3.000000      68.000000        1.000000  ...   \n",
       "\n",
       "       B_piece squares sum  B_diagonal control  B_center control  \\\n",
       "count        200000.000000       200000.000000     200000.000000   \n",
       "mean          -2685.581445           -0.440135         -4.128925   \n",
       "std            1110.500245            0.591141          1.795731   \n",
       "min           -4647.000000           -3.000000        -12.000000   \n",
       "25%           -3651.000000           -1.000000         -5.000000   \n",
       "50%           -2922.000000            0.000000         -4.000000   \n",
       "75%           -1745.000000            0.000000         -3.000000   \n",
       "max              54.000000            0.000000          0.000000   \n",
       "\n",
       "       B_doubled pawns     B_mobility  B_both bishops  B_not all pawns  \\\n",
       "count    200000.000000  200000.000000   200000.000000    200000.000000   \n",
       "mean         -0.122585     -31.543205       -0.386875        -0.879410   \n",
       "std           0.342722      11.501664        0.487036         0.325651   \n",
       "min          -3.000000     -68.000000       -1.000000        -1.000000   \n",
       "25%           0.000000     -39.000000       -1.000000        -1.000000   \n",
       "50%           0.000000     -34.000000        0.000000        -1.000000   \n",
       "75%           0.000000     -26.000000        0.000000        -1.000000   \n",
       "max           0.000000       0.000000        0.000000         0.000000   \n",
       "\n",
       "       B_pinned evaluation  B_attacker evalutation    B_has queen  \n",
       "count        200000.000000           200000.000000  200000.000000  \n",
       "mean             -0.150080               -3.641950      -0.686355  \n",
       "std               0.687342                3.351823       0.464621  \n",
       "min             -14.000000              -26.000000      -2.000000  \n",
       "25%               0.000000               -5.000000      -1.000000  \n",
       "50%               0.000000               -3.000000      -1.000000  \n",
       "75%               0.000000               -1.000000       0.000000  \n",
       "max               0.000000                0.000000       0.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_win = data[data[\"winner\"] == \"White\"]\n",
    "print(len(data_win))\n",
    "data_lose = data[data[\"winner\"] == \"Black\"]\n",
    "print(len(data_lose))\n",
    "data_draw = data[data[\"winner\"] == \"Draw\"]\n",
    "print(len(data_draw))\n",
    "\n",
    "data_win = data_win.sample(100_000)\n",
    "\n",
    "data_lose = data_lose.sample(100_000)\n",
    "\n",
    "data = data_win.append(data_lose)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = data.columns[4:]\n",
    "\n",
    "target = data[\"winner\"] != \"Black\"\n",
    "features = data[feature_cols]\n",
    "scaler =  MinMaxScaler()\n",
    "features_transformed = scaler.fit_transform(features)\n",
    "features = pd.DataFrame(features_transformed, columns=features.columns)\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, shuffle=True, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(8, 4, figsize=(100, 100))\n",
    "\n",
    "# for i in range(len(feature_cols)):\n",
    "#     sns.distplot(features[feature_cols[i]], ax=axs.flat[i])\n",
    "# #     sns.distplot(features[plot_cols[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_material sum</th>\n",
       "      <th>W_pawn control</th>\n",
       "      <th>W_piece squares sum</th>\n",
       "      <th>W_diagonal control</th>\n",
       "      <th>W_center control</th>\n",
       "      <th>W_doubled pawns</th>\n",
       "      <th>W_mobility</th>\n",
       "      <th>W_both bishops</th>\n",
       "      <th>W_not all pawns</th>\n",
       "      <th>W_pinned evaluation</th>\n",
       "      <th>...</th>\n",
       "      <th>B_piece squares sum</th>\n",
       "      <th>B_diagonal control</th>\n",
       "      <th>B_center control</th>\n",
       "      <th>B_doubled pawns</th>\n",
       "      <th>B_mobility</th>\n",
       "      <th>B_both bishops</th>\n",
       "      <th>B_not all pawns</th>\n",
       "      <th>B_pinned evaluation</th>\n",
       "      <th>B_attacker evalutation</th>\n",
       "      <th>B_has queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.590567</td>\n",
       "      <td>0.514007</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.121527</td>\n",
       "      <td>0.394230</td>\n",
       "      <td>0.047203</td>\n",
       "      <td>0.464099</td>\n",
       "      <td>0.38924</td>\n",
       "      <td>0.88433</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417479</td>\n",
       "      <td>0.853753</td>\n",
       "      <td>0.656290</td>\n",
       "      <td>0.959087</td>\n",
       "      <td>0.535901</td>\n",
       "      <td>0.612480</td>\n",
       "      <td>0.119250</td>\n",
       "      <td>0.989561</td>\n",
       "      <td>0.860430</td>\n",
       "      <td>0.656890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.237062</td>\n",
       "      <td>0.175038</td>\n",
       "      <td>0.232328</td>\n",
       "      <td>0.189984</td>\n",
       "      <td>0.167166</td>\n",
       "      <td>0.121599</td>\n",
       "      <td>0.168677</td>\n",
       "      <td>0.48758</td>\n",
       "      <td>0.31983</td>\n",
       "      <td>0.049804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236205</td>\n",
       "      <td>0.196805</td>\n",
       "      <td>0.149494</td>\n",
       "      <td>0.114269</td>\n",
       "      <td>0.168677</td>\n",
       "      <td>0.487186</td>\n",
       "      <td>0.324084</td>\n",
       "      <td>0.048215</td>\n",
       "      <td>0.128420</td>\n",
       "      <td>0.232381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.377390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211870</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.775977</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       W_material sum  W_pawn control  W_piece squares sum  \\\n",
       "count   100000.000000   100000.000000        100000.000000   \n",
       "mean         0.590567        0.514007             0.573335   \n",
       "std          0.237062        0.175038             0.232328   \n",
       "min          0.000000        0.000000             0.000000   \n",
       "25%          0.386364        0.500000             0.377390   \n",
       "50%          0.636364        0.500000             0.622195   \n",
       "75%          0.795455        0.500000             0.775977   \n",
       "max          0.886364        1.000000             0.896509   \n",
       "\n",
       "       W_diagonal control  W_center control  W_doubled pawns     W_mobility  \\\n",
       "count       100000.000000     100000.000000    100000.000000  100000.000000   \n",
       "mean             0.121527          0.394230         0.047203       0.464099   \n",
       "std              0.189984          0.167166         0.121599       0.168677   \n",
       "min              0.000000          0.000000         0.000000       0.000000   \n",
       "25%              0.000000          0.250000         0.000000       0.382353   \n",
       "50%              0.000000          0.416667         0.000000       0.500000   \n",
       "75%              0.333333          0.500000         0.000000       0.573529   \n",
       "max              1.000000          1.000000         1.000000       0.970588   \n",
       "\n",
       "       W_both bishops  W_not all pawns  W_pinned evaluation  ...  \\\n",
       "count    100000.00000     100000.00000        100000.000000  ...   \n",
       "mean          0.38924          0.88433             0.011062  ...   \n",
       "std           0.48758          0.31983             0.049804  ...   \n",
       "min           0.00000          0.00000             0.000000  ...   \n",
       "25%           0.00000          1.00000             0.000000  ...   \n",
       "50%           0.00000          1.00000             0.000000  ...   \n",
       "75%           1.00000          1.00000             0.000000  ...   \n",
       "max           1.00000          1.00000             1.000000  ...   \n",
       "\n",
       "       B_piece squares sum  B_diagonal control  B_center control  \\\n",
       "count        100000.000000       100000.000000     100000.000000   \n",
       "mean              0.417479            0.853753          0.656290   \n",
       "std               0.236205            0.196805          0.149494   \n",
       "min               0.000000            0.000000          0.000000   \n",
       "25%               0.211870            0.666667          0.583333   \n",
       "50%               0.367794            1.000000          0.666667   \n",
       "75%               0.617741            1.000000          0.750000   \n",
       "max               0.998936            1.000000          1.000000   \n",
       "\n",
       "       B_doubled pawns     B_mobility  B_both bishops  B_not all pawns  \\\n",
       "count    100000.000000  100000.000000   100000.000000    100000.000000   \n",
       "mean          0.959087       0.535901        0.612480         0.119250   \n",
       "std           0.114269       0.168677        0.487186         0.324084   \n",
       "min           0.000000       0.029412        0.000000         0.000000   \n",
       "25%           1.000000       0.426471        0.000000         0.000000   \n",
       "50%           1.000000       0.500000        1.000000         0.000000   \n",
       "75%           1.000000       0.617647        1.000000         0.000000   \n",
       "max           1.000000       1.000000        1.000000         1.000000   \n",
       "\n",
       "       B_pinned evaluation  B_attacker evalutation    B_has queen  \n",
       "count        100000.000000           100000.000000  100000.000000  \n",
       "mean              0.989561                0.860430       0.656890  \n",
       "std               0.048215                0.128420       0.232381  \n",
       "min               0.000000                0.000000       0.000000  \n",
       "25%               1.000000                0.807692       0.500000  \n",
       "50%               1.000000                0.884615       0.500000  \n",
       "75%               1.000000                0.961538       1.000000  \n",
       "max               1.000000                1.000000       1.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_features=None, n_estimators=400, n_jobs=-1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "estimator_et = sklearn.ensemble.ExtraTreesClassifier(n_estimators=400, n_jobs=-1, max_features=None)\n",
    "\n",
    "clf = estimator_et\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99914\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "estimator = clf\n",
    "train_acc = estimator.score(x_train, y_train)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77836\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy\n",
    "test_acc = estimator.score(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88875"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy of training  + testing with a 95/5 split\n",
    "#this is kind of bad? we need a seperate games database, for example you might have a\n",
    "#state one move away in training and testing\n",
    "((len(x_train) * train_acc) + (len(x_test) * test_acc))/ len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(x_test)\n",
    "y_true = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49955"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler =  MinMaxScaler()\n",
    "draws = data_draw[feature_cols]\n",
    "draws_transformed = scaler.fit_transform(draws)\n",
    "features_draw = pd.DataFrame(features_transformed, columns=features.columns)\n",
    "###this is the accuracy of applying the model to only drawn states\n",
    "sum(estimator.predict(features_draw))/len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data  = pd.read_csv(\"evaluations.csv\")\n",
    "x_new = new_data[data.columns[4:]]\n",
    "x_new\n",
    "y_true_new = list(new_data[\"winner\"] == \"White\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  MinMaxScaler()\n",
    "new_data = scaler.fit_transform(x_new)\n",
    "new_data = pd.DataFrame(new_data, columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_new = list(estimator.predict(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###this is the accuracy for every bit of data, trainign + testing + draws\n",
    "estimator.score(new_data, y_true_new) #factoring in draws its correct 50% of the time with draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), fontsize=20,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"yellow\" if cm[i, j] > thresh else \"red\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(metrics.confusion_matrix(y_true, y_pred), classes=[\"Win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_metrix(y_true, y_pred):\n",
    "    CM = metrics.confusion_matrix(y_true, y_pred)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    Population = TN + FN + TP + FP\n",
    "    Prevalence = round((TP + FP) / Population, 3)\n",
    "    Accuracy = round((TP + TN) / Population, 3)\n",
    "    Precision = round(TP / (TP + FP), 3)\n",
    "    NPV = round(TN / (TN + FN), 3)\n",
    "    FDR = round(FP / (TP + FP), 3)\n",
    "    FOR = round(FN / (TN + FN), 3)\n",
    "    check_Pos = Precision + FDR\n",
    "    check_Neg = NPV + FOR\n",
    "    Recall = round(TP / (TP + FN), 3)\n",
    "    FPR = round(FP / (TN + FP), 3)\n",
    "    Specificity = 1 - FPR\n",
    "    FNR = round(FN / (TP + FN), 3)\n",
    "    TNR = round(TN / (TN + FP), 3)\n",
    "    check_Pos2 = Recall + FNR\n",
    "    check_Neg2 = FPR + TNR\n",
    "    LRPos = round(Recall / FPR, 3)\n",
    "    LRNeg = round(FNR / TNR, 3)\n",
    "    DOR = round(LRPos / LRNeg)\n",
    "    F1 = round(2 * ((Precision * Recall) / (Precision + Recall)), 4)\n",
    "    F2 = round((1 + 2 ** 2) * ((Precision * Recall) / ((2 ** 2 * Precision) + Recall)), 4)\n",
    "    MCC = -1\n",
    "#     MCC = round(((TP * TN) - (FP * FN)) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)), 4)\n",
    "    BM = Recall + TNR - 1\n",
    "    MK = Precision + NPV - 1\n",
    "#     AUC = round(metrics.roc_auc_score(y_true, prediction), 3)\n",
    "\n",
    "    met_dict = {\n",
    "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN, 'Prevalence': Prevalence,\n",
    "        'Accuracy': Accuracy, 'Precision': Precision, 'Recall': Recall,\n",
    "        'F1': F1, 'F2': F2,\n",
    "        # 'AUC':AUC,\n",
    "        'NPV': NPV, 'FPR': FPR,\n",
    "        'TNR': Specificity, 'FNR': FNR, 'TNR': TNR, 'FDR': FDR, 'FOR': FOR, 'check_Pos': check_Pos,\n",
    "        'check_Neg': check_Neg, 'check_Pos2': check_Pos2, 'check_Neg2': check_Neg2, 'LR+': LRPos,\n",
    "        'LR-': LRNeg, 'DOR': DOR, 'MCC': MCC, 'BM': BM, 'MK': MK\n",
    "    }\n",
    "\n",
    "    return met_dict\n",
    "matrix_metrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
